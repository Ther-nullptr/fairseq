{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 2])\n",
      "torch.Size([3, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "code_book = torch.tensor([[0,1],[2,3],[4,5],[6,7],[8,9]])\n",
    "proj_data = torch.tensor([[[1,2],[3,4],[5,6]],[[7,8],[9,10],[11,12]],[[13,14],[15,16],[17,18]]])\n",
    "print(code_book.shape) # [vocab_size, code_book_dim]\n",
    "print(proj_data.shape) # [batch_size, seq_len, embedding_dim(same as embedding dim)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[  2,   2,  18,  50,  98],\n",
      "         [ 18,   2,   2,  18,  50],\n",
      "         [ 50,  18,   2,   2,  18]],\n",
      "\n",
      "        [[ 98,  50,  18,   2,   2],\n",
      "         [162,  98,  50,  18,   2],\n",
      "         [242, 162,  98,  50,  18]],\n",
      "\n",
      "        [[338, 242, 162,  98,  50],\n",
      "         [450, 338, 242, 162,  98],\n",
      "         [578, 450, 338, 242, 162]]]) torch.Size([3, 3, 5])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 4],\n",
      "        [4, 4, 4]]) torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "proj_data = torch.unsqueeze(proj_data,2)\n",
    "tmp = torch.sub(proj_data,code_book)\n",
    "norm2 = torch.squeeze(torch.sum(tmp ** 2, dim=-1)) # get the distance between each vector and each codebook\n",
    "print(norm2,norm2.shape)\n",
    "labels = torch.argmin(norm2, dim=-1) # get the index of the nearest codebook\n",
    "print(labels, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "labels = torch.unsqueeze(labels.flatten()[0:5],0)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = torch.tensor([[100,-10,0,0,0],[0,0,0,0,0],[1,2,10,1,1],[1,1,5,100,1],[1,1,1,1,100]])\n",
    "output = torch.unsqueeze(output,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5267)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(output.float(), labels)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "beb7ff9966cbdd4ea42a048596890942ce3677941e544582b862184b436bb673"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('fairseq')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
